function [label, model, llh] = mixGaussEmExtension(models, init)
% Perform Extend EM algorithm for fitting the Gaussian mixture model.
% Input: 
%   models: 1 x I(total number of images in each class) data matrix
%           each data in this matrix is a model generated by EM algorithm
%           model.miu: a d-by-k matrix.
%           model.Sigma: a d-by-d-by-k matrix.
%           model.w: a 1-by-k vector.
%   init: M (1 x 1) number of components or label (1 x n, 1<=label(i)<=k) or model structure
% Output:
%   label: 1 x n cluster label
%   model: trained model structure
%          model.mu: a d-by-m matrix.
%          model.Sigma: a d-by-d-by-m matrix.
%          model.w: a 1-by-m vector.
%   llh: loglikelihood

fprintf('Extend EM for Gaussian mixture: running ... \n');
%将models里面的struct格式变成matrix
%n=I*k
%X是model.miu转换而来，维度是：d*n
%W_JK是model.w转换而来，维度是：1*n
%SIGMA_JK是model.Sigma转换而来，维度是：d*d*n
[X, W_JK, SIGMA_JK]= transModels(models);
save('X.mat','X')
tol = 1e-15;
maxiter = 500;
llh = -inf(1,maxiter);
[model,R,label] = initialization(X,init,W_JK,SIGMA_JK);
for iter = 2:maxiter
    size(R);
    [R, llh(iter)] = expectation(X,model,W_JK,SIGMA_JK);
    [~,label(1,:)] = max(R,[],2);
    R = R(:,unique(label));   % remove empty clusters
    model = maximization(X,R,W_JK,SIGMA_JK);
    if abs(llh(iter)-llh(iter-1)) < tol*abs(llh(iter)); break; end;
end
llh = llh(2:iter);
end


function [model,R,label] = initialization(X, init,W_JK,SIGMA_JK)
[d,n] = size(X);
model = [];
R = [];
label=[];
if isstruct(init)  % init with a model
    model = init;
    R  = expectation(X,model,W_JK,SIGMA_JK);
elseif numel(init) == 1  % random init k
    m = init;
    label = ceil(m*rand(1,n));
    label = mod(1:n, m); 
    label(m:m:n) = m;
    R = full(sparse(1:n,label,1,n,m,n));
    w_tmp = randi([1,100],1,m);
    model.w = w_tmp/sum(w_tmp);
    rndp = randperm(n);
    if m>n
        index=randi([1,n],1,m);
    else
        index=rndp(1:m);
    end
    model.mu =  X(:,index);
    model.Sigma = SIGMA_JK(:,:,index);
else
    error('ERROR: init is not valid.');
end
end


function [X, W_JK, SIGMA_JK]= transModels(models)
X = [];
W_JK = [];
SIGMA_JK = [];
I = size(models,2);%一个类里面图片的数量
for i=1:I
    X = [X,models(i).mu];
    W_JK = [W_JK,models(i).w];
    SIGMA_JK = cat(3,SIGMA_JK,models(i).Sigma);
end
end


function [R, llh] = expectation(X, model, W_JK,SIGMA_JK)
mu = model.mu;
Sigma = model.Sigma;
w = model.w;

n = size(X,2);
m = size(mu,2);
R = zeros(n,m);
for i = 1:m
    R(:,i) = loggausspdf(X,mu(:,i),Sigma(:,:,i));
    for j = 1:n      
        R(j,i) = (R(j,i)-0.5*trace(Sigma(:,:,i)\SIGMA_JK(:,:,j)))*W_JK(j);
    end
end
R = bsxfun(@plus,R,log(w));
T = logsumexp(R,2);
llh = sum(T); % loglikelihood
R = exp(bsxfun(@minus,R,T));
end

function model = maximization(X,R,W_JK,SIGMA_JK)
[d,n] = size(X);
m = size(R,2);
w = sum(R,1)/n;%1*m
w_tmp = bsxfun(@times,W_JK',R);
w_m_jk = bsxfun(@rdivide, w_tmp, sum(w_tmp,1));%n*m
mu = X*w_m_jk;%d*m
Sigma = zeros(d,d,m);
for i = 1:m
    miu_shift = bsxfun(@minus, X, mu(:,i));%d*n
    sig_tmp = bsxfun(@plus, SIGMA_JK, miu_shift*miu_shift');%d*d*n
    Sigma(:,:,i) = sum(bsxfun(@times,reshape(w_m_jk(:,i),[1,1,n]),sig_tmp),3)+eye(d)*(1e-4);
end

model.mu = mu;
model.Sigma = Sigma;
model.w = w;
end

function y = loggausspdf(X, mu, Sigma)
d = size(X,1);
X = bsxfun(@minus,X,mu);
[U,p]= chol(Sigma);
if p ~= 0
    error('ERROR: Sigma is not PD.');
end
Q = U'\X;
q = dot(Q,Q,1);  % quadratic term (M distance)
c = d*log(2*pi)+2*sum(log(diag(U)));   % normalization constant
y = -(c+q)/2;
end